# -*- coding: utf-8 -*-
"""Traffic Sign.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Q-qXHAuLpjblTbjOWwYPAn4IoFIxmMJ
"""

!git clone https://bitbucket.org/jadslim/german-traffic-signs

!ls german-traffic-signs

import numpy as np
import matplotlib.pyplot as plt
import random
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout
from keras.layers.convolutional import Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import Adam
import pickle
# thư viện dùng để đọc file excel .csv
import pandas as pd

# lấy data traffic sign từ tập dữ liệu german-traffic-signs
# unpickle object từ file test.p
with open('german-traffic-signs/test.p', 'rb') as f:
  test_data = pickle.load(f)
with open('german-traffic-signs/train.p', 'rb') as f:
  train_data = pickle.load(f)
with open('german-traffic-signs/valid.p', 'rb') as f:
  valid_data = pickle.load(f)
print(type(test_data))
# dataset ở trên là một cặp dict chứa feature biển báo và label tương ứng với biển báo đó
X_test, y_test = test_data['features'], test_data['labels']
X_train, y_train = train_data['features'], train_data['labels']
X_val, y_val = valid_data['features'], valid_data['labels']

print(X_train.shape)
print(X_test.shape)
print(X_val.shape)

assert(X_train.shape[0] == y_train.shape[0]), 'The number of images is not equal to the number of labels'
assert(X_test.shape[0] == y_test.shape[0]), 'The number of images is not equal to the number of labels'
assert(X_val.shape[0] == y_val.shape[0]), 'The number of images is not equal to the number of labels'
assert(X_train.shape[1:] == (32,32,3)), 'The dimensions of images is not equal 32x32x3'
assert(X_test.shape[1:] == (32,32,3)), 'The dimensions of images is not equal 32x32x3'
assert(X_val.shape[1:] == (32,32,3)), 'The dimensions of images is not equal 32x32x3'

data = pd.read_csv('german-traffic-signs/signnames.csv')
num_of_samples = []
cols = 5
num_classes = data.shape[0]
fig, ax = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5,50))
plt.tight_layout()
for i in range(cols):
  # data.iterrows() gồm (index, series)
  # index là cột thứ tự
  # series là cột SignName
  for j, row in data.iterrows():
    x_selected = X_train[y_train==j]
    ax[j][i].imshow(x_selected[random.randint(0, len(x_selected-1)),:,:,:], cmap=plt.get_cmap('gray'))
    ax[j][i].axis('off')
    if i==2:
      ax[j][i].set_title(str(j) + '-' + row['SignName'])
      num_of_samples.append(len(x_selected))

plt.figure(figsize=(12,4))
plt.bar(range(0, num_classes), num_of_samples)
plt.xlabel('Class number')
plt.ylabel('The number of images')
plt.title('The distribution of train datasets')
print(num_of_samples)

# Import một image để xử lí
import cv2
plt.imshow(X_train[1000])
plt.axis("off")
print(X_train[1000].shape)
print(y_train[1000])

# convert gray image để histogram equalization
def gray_scale(img):
  img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
  return img
img = gray_scale(X_train[1000])
plt.imshow(img, cmap=plt.get_cmap('gray'))
plt.axis('off')
print(img.shape)

# histogram equalization giúp cân bằng độ sáng image và tăng độ tương phản
def equalize(img):
  img = cv2.equalizeHist(img)
  return img
img = equalize(img)
plt.imshow(img, cmap=plt.get_cmap('gray'))
plt.axis('off')

# Áp dụng bước pre-processing cho toàn bộ dataset
def preprocessing(img):
  img = gray_scale(img)
  img = equalize(img)
  img = img/255
  return img
# hàm map có chức năng thực hiện hàm preprocessing cho tất cả image trong X_train
# trả về kiểu list để đến bước tiếp theo là imshow image
# np.array biến thành array để imshow
X_train = np.array(list(map(preprocessing, X_train)))
X_test = np.array(list(map(preprocessing, X_test)))
X_val = np.array(list(map(preprocessing, X_val)))

# imshow image để xem kết quả xử lí
plt.imshow(X_train[random.randint(0, len(X_train-1))], cmap=plt.get_cmap('gray'))
plt.axis('off')
print(X_train.shape)

# reshape image dimensions và label one hot coding để đưa vào training model
X_train = X_train.reshape(34799, 32, 32, 1)
X_test = X_test.reshape(12630, 32, 32, 1)
X_val = X_val.reshape(4410, 32, 32, 1)
y_train = to_categorical(y_train, 43)
y_test = to_categorical(y_test, 43)
y_val = to_categorical(y_val, 43)

# data augmentation technique
from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(width_shift_range=0.1,
                             height_shift_range=0.1,
                             zoom_range=0.2,
                             shear_range=0.1,
                             rotation_range=10)

# model xử lí các bước trên với tập X_train
datagen.fit(X_train)   
# tạo data mới từ tập X_train, mỗi lặp lại sẽ chọn 20 image bất kì để thực hiện
batches = datagen.flow(X_train, y_train, batch_size=50)
# X_batch sẽ lưu trữ các image mới tạo ra từ batches
# next(batches) trả về các phần tử được tạo ra tiếp theo của iterator batches
X_batch, y_batch = next(batches)
fig, ax = plt.subplots(1, 20, figsize=(20,5))
for i in range(20):
  ax[i].imshow(X_batch[i].reshape(32,32), cmap=plt.get_cmap('gray'))
  ax[i].axis('off')

def leNet_model():
  model = Sequential()
  model.add(Conv2D(filters=60, kernel_size=(5,5), input_shape=(32,32,1), activation='relu', strides=1, padding='valid'))
  model.add(Conv2D(filters=60, kernel_size=(5,5), input_shape=(32,32,1), activation='relu', strides=1, padding='valid'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  model.add(Conv2D(filters=30, kernel_size=(3,3), activation='relu'))
  model.add(Conv2D(filters=30, kernel_size=(3,3), activation='relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))
  #model.add(Dropout(rate=0.5))
  model.add(Flatten())
  model.add(Dense(units=500, activation='relu'))
  model.add(Dropout(rate=0.5))
  model.add(Dense(units=num_classes, activation='softmax'))
  model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics='Accuracy')
  return model

model = leNet_model()
#print(model.summary())
h = model.fit(datagen.flow(X_train, y_train, batch_size=50), 
              steps_per_epoch=695, 
              epochs=10, 
              verbose=1,
              validation_data=(X_val,y_val), 
              shuffle=1)

plt.plot(h.history['Accuracy'])
plt.plot(h.history['val_Accuracy'])
plt.legend(['Accuracy','val_Accuracy'])
plt.xlabel('epoch')
plt.title('Accuracy')

plt.plot(h.history['loss'])
plt.plot(h.history['val_loss'])
plt.legend(['loss','val_loss'])
plt.xlabel('epoch')
plt.title('loss')

score = model.evaluate(X_test, y_test, verbose=0)
print('loss:', score[0])
print('accuracy',score[1])

# Nhận dạng 1 biển báo lấy từ web
import requests   
from PIL import Image
url = 'https://cdn.images.fecom-media.com/FE00007318/images/HE1318852_1318852-P.jpg'
response = requests.get(url, stream=True)
img = Image.open(response.raw)
plt.imshow(img)

import cv2
img_array = np.asarray(img)
img_resized = cv2.resize(img_array, (32,32))
img = preprocessing(img_resized)
plt.imshow(img, cmap=plt.get_cmap('gray'))

img = img.reshape(1,32,32,1)
prediction = model.predict(img)
prediction = np.argmax(prediction, axis=1)
print('Prediction:',prediction)

